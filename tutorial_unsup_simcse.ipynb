{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# データの前処理\n"
      ],
      "metadata": {
        "id": "ueEmvJ6S3cow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wikipediaからテキストファイルをダウンロードする"
      ],
      "metadata": {
        "id": "Cs9KM3VB3m-b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3DGtzkE3cDz",
        "outputId": "036cbc59-8652-48a7-9cdd-4bcbbb0a680a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-13 04:43:07--  https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/wiki1m_for_simcse.txt\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.59, 3.165.160.11, 3.165.160.12, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/621ffdd236468d709f183d48/af65686a27c825e2fbe0c13f49573907a8ec57d7417f82062de6b1c67aa69462?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27wiki1m_for_simcse.txt%3B+filename%3D%22wiki1m_for_simcse.txt%22%3B&response-content-type=text%2Fplain&Expires=1768282987&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY4MjgyOTg3fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjIxZmZkZDIzNjQ2OGQ3MDlmMTgzZDQ4L2FmNjU2ODZhMjdjODI1ZTJmYmUwYzEzZjQ5NTczOTA3YThlYzU3ZDc0MTdmODIwNjJkZTZiMWM2N2FhNjk0NjJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=RaFqHHQS-cJglKm1IeG-Yw4wZhGWMZLL9Hx3j8DkMiDXjeeG6pTSue1E0ogK5RK4Ii4Qh0Wa%7EjFWVftuEVxAJvlP8jaeQqgqzCyxOCZodqtZq%7EAFiINniefGRs2bt2WyrRMnwTC8wGX4O%7E7B5nzaRNFb1lLSXgZKdBFoDjixR1Fc%7ElA0Lc9E3qa80iFdS%7EB3ZDTtF7FHS57GhzbkJ5oSrj18ci6ipj2J2EREz1HhOw-bOjEh8V6D7hXA2PzIsvwHhXfZo5xOyzv3qvbJfE31%7EwntODgrb4IzWx6NnsuY8IyKJVmwJFFxpIZFfZv0ncUZuUOPA16CKuZTibWcgup3zQ__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-01-13 04:43:07--  https://us.gcp.cdn.hf.co/xet-bridge-us/621ffdd236468d709f183d48/af65686a27c825e2fbe0c13f49573907a8ec57d7417f82062de6b1c67aa69462?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27wiki1m_for_simcse.txt%3B+filename%3D%22wiki1m_for_simcse.txt%22%3B&response-content-type=text%2Fplain&Expires=1768282987&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzY4MjgyOTg3fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjIxZmZkZDIzNjQ2OGQ3MDlmMTgzZDQ4L2FmNjU2ODZhMjdjODI1ZTJmYmUwYzEzZjQ5NTczOTA3YThlYzU3ZDc0MTdmODIwNjJkZTZiMWM2N2FhNjk0NjJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=RaFqHHQS-cJglKm1IeG-Yw4wZhGWMZLL9Hx3j8DkMiDXjeeG6pTSue1E0ogK5RK4Ii4Qh0Wa%7EjFWVftuEVxAJvlP8jaeQqgqzCyxOCZodqtZq%7EAFiINniefGRs2bt2WyrRMnwTC8wGX4O%7E7B5nzaRNFb1lLSXgZKdBFoDjixR1Fc%7ElA0Lc9E3qa80iFdS%7EB3ZDTtF7FHS57GhzbkJ5oSrj18ci6ipj2J2EREz1HhOw-bOjEh8V6D7hXA2PzIsvwHhXfZo5xOyzv3qvbJfE31%7EwntODgrb4IzWx6NnsuY8IyKJVmwJFFxpIZFfZv0ncUZuUOPA16CKuZTibWcgup3zQ__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120038621 (114M) [text/plain]\n",
            "Saving to: ‘wiki1m_for_simcse.txt.1’\n",
            "\n",
            "wiki1m_for_simcse.t 100%[===================>] 114.48M  48.0MB/s    in 2.4s    \n",
            "\n",
            "2026-01-13 04:43:10 (48.0 MB/s) - ‘wiki1m_for_simcse.txt.1’ saved [120038621/120038621]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/wiki1m_for_simcse.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_FILE_PATH = \"wiki1m_for_simcse.txt\""
      ],
      "metadata": {
        "id": "U4qGcTzd3mNr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDN1oVC83uw6",
        "outputId": "5e343e18-2727-4e16-8402-81f1c379946f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  tokenized_text = word_tokenize(text)\n",
        "\n",
        "  # 10単語以上50単語以下の単語のみを使用する\n",
        "  if 10 <= len(tokenized_text) and len(tokenized_text) <=50:\n",
        "    return text.strip()\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "ogThMRB24J6s"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TEXT_FILE_PATH, \"r\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "input_texts = list(filter(lambda line: preprocess(line) is not None, lines))\n"
      ],
      "metadata": {
        "id": "b_LtALCL5Fka"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 対照学習"
      ],
      "metadata": {
        "id": "sFco-yls8ZVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from transformers.trainer_utils import set_seed\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import TrainingArguments\n",
        "from datasets import Dataset\n",
        "from transformers import Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "import sys\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fsFwkX-48xmu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"google-bert/bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "id": "olZkcieY_hXf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fix_seed(42)"
      ],
      "metadata": {
        "id": "e-U0q4HQ8z-c"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_collate_fn(examples):\n",
        "  tokenized_sent = tokenizer(\n",
        "      [example[\"text\"] for example in examples],\n",
        "      padding=True,\n",
        "      return_tensors=\"pt\",\n",
        "  )\n",
        "  labels = torch.arange(len(examples))\n",
        "\n",
        "  return {\n",
        "      \"tokenized_texts_1\": tokenized_sent,\n",
        "      \"tokenized_texts_2\": tokenized_sent,\n",
        "      \"labels\": labels,\n",
        "  }\n"
      ],
      "metadata": {
        "id": "Sr78u611_Kdv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_collate_fn(examples):\n",
        "\n",
        "  tokenized_sent = tokenizer(\n",
        "      [example[\"text\"] for example in examples],\n",
        "      padding=True,\n",
        "      return_tensors=\"pt\",\n",
        "  )\n",
        "\n",
        "  labels = torch.arange(len(examples))\n",
        "\n",
        "  return {\n",
        "      \"tokenized_texts_1\": tokenized_sent,\n",
        "      \"tokenized_texts_2\": tokenized_sent,\n",
        "      \"labels\": labels,\n",
        "  }\n"
      ],
      "metadata": {
        "id": "T20qnrbW_Q1o"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCSEModel(nn.Module):\n",
        "  \"\"\"SimCSEのモデル\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      base_model_name,\n",
        "      mlp_only_train = False,\n",
        "      temperature = 0.05,\n",
        "  ):\n",
        "      \"\"\"モデルの初期化\"\"\"\n",
        "      super().__init__()\n",
        "\n",
        "      self.encoder = AutoModel.from_pretrained(base_model_name)\n",
        "\n",
        "      # MLP層の次元数\n",
        "      self.hidden_size = self.encoder.config.hidden_size\n",
        "      # MLP層の線形層\n",
        "      self.dense = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "      # MLP層の活性化関数\n",
        "      self.activation = nn.Tanh()\n",
        "\n",
        "      self.mlp_only_train = mlp_only_train\n",
        "      # 交差エントロピー損失の計算時に使用する温度\n",
        "      self.temperature = temperature\n",
        "\n",
        "  def encode_texts(self, tokenized_texts):\n",
        "      \"\"\"エンコーダを用いて文をベクトルに変換\"\"\"\n",
        "      encoded_texts = self.encoder(**tokenized_texts)\n",
        "\n",
        "      encoded_texts = encoded_texts.last_hidden_state[:, 0]\n",
        "\n",
        "      if self.mlp_only_train and not self.training:\n",
        "          return encoded_texts\n",
        "\n",
        "      # MLP層によるベクトルの変換を行う\n",
        "      encoded_texts = self.dense(encoded_texts)\n",
        "      encoded_texts = self.activation(encoded_texts)\n",
        "\n",
        "      return encoded_texts\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      tokenized_texts_1,\n",
        "      tokenized_texts_2,\n",
        "      labels):\n",
        "      \"\"\"モデルの前向き計算を定義\"\"\"\n",
        "      # 文ペアをベクトルに変換する\n",
        "\n",
        "      encoded_texts_1 = self.encode_texts(tokenized_texts_1)\n",
        "      encoded_texts_2 = self.encode_texts(tokenized_texts_2)\n",
        "\n",
        "      # 文ペアの類似度行列を作成する\n",
        "      sim_matrix = F.cosine_similarity(\n",
        "          encoded_texts_1.unsqueeze(1),\n",
        "          encoded_texts_2.unsqueeze(0),\n",
        "          dim=2,\n",
        "      )\n",
        "\n",
        "      loss = F.cross_entropy(sim_matrix / self.temperature, labels)\n",
        "\n",
        "      return {\"loss\": loss}"
      ],
      "metadata": {
        "id": "SbBuRfqg9EEf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCSETrainer(Trainer):\n",
        "  \"\"\"SimCSEの訓練に使用するTrainer\"\"\"\n",
        "  def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "      labels = inputs.pop(\"labels\")\n",
        "\n",
        "      if self.model.training:\n",
        "          outputs = model(**inputs, labels=labels)\n",
        "          loss = outputs[\"loss\"]\n",
        "          return loss\n",
        "      else:\n",
        "          outputs = model(**inputs, labels=labels)\n",
        "          loss = outputs[\"loss\"]\n",
        "          return loss, outputs\n",
        "\n",
        "  def get_eval_dataloader(self, eval_dataset):\n",
        "\n",
        "      if eval_dataset is None:\n",
        "          eval_dataset = self.eval_dataset\n",
        "\n",
        "      return DataLoader(\n",
        "          eval_dataset,\n",
        "          batch_size=64,\n",
        "          collate_fn=eval_collate_fn,\n",
        "          pin_memory=True,\n",
        "      )"
      ],
      "metadata": {
        "id": "gQ6uvpNd9j6E"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sup_model = SimCSEModel(model, mlp_only_train=False)"
      ],
      "metadata": {
        "id": "c-puSJ_b96Jx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_dict({\"text\": input_texts[:20000]})\n",
        "dev_dataset = Dataset.from_dict({\"text\": input_texts[20000:22000]})"
      ],
      "metadata": {
        "id": "RZTR8D2R_xXf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sup_training_args = TrainingArguments(\n",
        "    output_dir=\"./save_model\",\n",
        "    per_device_train_batch_size=64,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=1,\n",
        "    fp16=False,\n",
        "    remove_unused_columns=False,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "sup_trainer = SimCSETrainer(\n",
        "    model=sup_model,\n",
        "    args=sup_training_args,\n",
        "    data_collator=train_collate_fn,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(3)],\n",
        ")\n",
        "\n",
        "sup_trainer.train()\n",
        "sup_model.encoder.save_pretrained(\"./save_model\")\n",
        "tokenizer.save_pretrained(\"./save_model\")"
      ],
      "metadata": {
        "id": "Kdtrqb1a8asi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "ca3339d2-c018-4733-f656-2dbb80f1084f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [313/313 06:54, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.008754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./save_model/tokenizer_config.json',\n",
              " './save_model/special_tokens_map.json',\n",
              " './save_model/vocab.txt',\n",
              " './save_model/added_tokens.json',\n",
              " './save_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 評価"
      ],
      "metadata": {
        "id": "Viq-PH9Roze-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "stsb_test = load_dataset(\"sentence-transformers/stsb\", split=\"test\")\n",
        "\n",
        "\n",
        "sentences1 = list(stsb_test[\"sentence1\"])\n",
        "sentences2 = list(stsb_test[\"sentence2\"])\n",
        "gold_scores = list(stsb_test[\"score\"])"
      ],
      "metadata": {
        "id": "oZhfSlnZnG-o"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def get_embeddings(model, tokenizer, sentences):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model.encoder(**inputs)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "    return embeddings\n",
        "\n",
        "embeddings1 = get_embeddings(sup_model, tokenizer, sentences1)\n",
        "embeddings2 = get_embeddings(sup_model, tokenizer, sentences2)\n",
        "\n",
        "cosine_sims = []\n",
        "for e1, e2 in zip(embeddings1, embeddings2):\n",
        "    sim = cosine_similarity(e1.reshape(1, -1), e2.reshape(1, -1))[0][0]\n",
        "    cosine_sims.append(sim)"
      ],
      "metadata": {
        "id": "phZxazSbpjXs"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# スピアマン相関係数の計算\n",
        "spearman_corr, _ = spearmanr(gold_scores, cosine_sims)\n",
        "\n",
        "print(f\"STSB Test Spearman Correlation: {spearman_corr:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTyXPjRZpsk0",
        "outputId": "342da363-0a39-4e11-fa0d-c04f4d38f01e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STSB Test Spearman Correlation: 0.5400\n"
          ]
        }
      ]
    }
  ]
}